{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('testenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "65a42bdb2f4fd1e2963f63fbecc12d40428c78ad536e43f0559247f991c7d5d2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize as wt \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import importlib\n",
    "import src.models as model\n",
    "importlib.reload(model)\n",
    "import src.utils as util\n",
    "importlib.reload(util);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'wt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ca0a69ea94f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtraining_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/covid_training.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/covid_test_public.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtraining_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\file\\Sm6\\Comp472\\Assign\\3\\Assignment_3\\src\\util.py\u001b[0m in \u001b[0;36mpreProcess\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# tokenising\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mtokenized_sms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# remove stop words and stemming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wt' is not defined"
     ]
    }
   ],
   "source": [
    "# global data\n",
    "training_set = pd.read_csv(\"data/covid_training.tsv\", sep=\"\\t\")\n",
    "test_set = pd.read_csv(\"data/covid_test_public.tsv\", sep=\"\\t\")\n",
    "training_set = util.preProcess(training_set)\n",
    "X = training_set.values[:,1].reshape(-1, 1)\n",
    "y = training_set.values[:,2].reshape(-1, 1)\n",
    "X_test = test_set.values[:,1].reshape(-1, 1)\n",
    "y_test = test_set.values[:,2].reshape(-1, 1)\n",
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, train_size=0.9, random_state=0)\n",
    "print(X_train.type)\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n",
    "#     X, y, train_size=0.9, random_state=0)\n",
    "# X_val, X_test, y_val, y_test = sklearn.model_selection.train_test_split(\n",
    "#     X_temp, y_temp, train_size=0.5, random_state=0)\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# main\n",
    "def process(input):\n",
    "    for index, e in enumerate(input):\n",
    "        print(f\"***\\t\\tsample {index}\\t\\t***\")\n",
    "        t=xpuzzle.XPuzzle(2, 4, input[index]) \n",
    "        s=search.Search(t, 30)\n",
    "\n",
    "        p = s.uniformCost()\n",
    "        print(p[0])\n",
    "        exportData(\"ucs\", index, p)\n",
    "\n",
    "        for heuristic in range(2):\n",
    "            p = s.greedyBFS(heuristic)\n",
    "            print(p[0])\n",
    "            exportData(\"gbfs\", index, p, heuristic)\n",
    "\n",
    "            p  = s.aStar(heuristic)\n",
    "            print(p[0])\n",
    "            exportData(\"astar\", index, p, heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = importData('samplePuzzles.txt')\n",
    "print(inputData, end='\\n\\n')\n",
    "process(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputData = importData('samplePuzzles.txt')\n",
    "print(inputData, end='\\n\\n')\n",
    "#inputData[4] no solution\n",
    "index = 4\n",
    "t=xpuzzle.XPuzzle(2, 4, inputData[index]) \n",
    "t.printPuzzle()\n",
    "s=search.Search(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}